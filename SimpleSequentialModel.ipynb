{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleSequentialModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcosma/DeepLearningTutorials/blob/master/SimpleSequentialModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg1TmIbqdRV6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Tutorial: HOW TO Create your first Sequential Model in Keras** \n",
        "\n",
        "by Dr Georgina Cosma\n",
        "\n",
        "This tutorial is based on  \n",
        "\n",
        "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WAVoe6SpMZU",
        "colab_type": "text"
      },
      "source": [
        "Learning outcomes:\n",
        "* Load Data.\n",
        "* Define a Sequential model.\n",
        "* Compile Model.\n",
        "* Evaluate Model.\n",
        "\n",
        "\n",
        "**Not using Colab?** If you are not using Colab you will need to Setup a Python Environment for \n",
        "Machine Learning and Deep Learning with Anaconda. You must have Python 2 or 3 \n",
        "installed and configured. You must install SciPy (including NumPy) and the relevant\n",
        "libraries including Keras. \n",
        "\n",
        "**Using Colab:** Some difficulties may be\n",
        "experienced with mounting, but the code and explanation here will help you overcome these. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Rq10MgkEOM",
        "colab_type": "text"
      },
      "source": [
        "**Step 1: Import libraries** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJYbRn_jdSBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I34xdjC4kTVk",
        "colab_type": "text"
      },
      "source": [
        "**Step 2: Mount to Google Drive in order to access your data file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqvH4wcpkbRj",
        "colab_type": "code",
        "outputId": "b03cb041-3e61-4a94-f62b-0a1a7194f42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#!ls \"/content/drive/My Drive/Colab Notebooks\"\n",
        "\n",
        "#if you need to remount\n",
        "#drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "#If you want to unmount and reset then: \n",
        "#Step 1: From the menu select Runtime--->Reset all Runtimes... \n",
        "#Step 2: Runtime--->Run all or you can run each Cell at a time. There will be a message \n",
        "# \"Go to a URL in a browser\" and you must click on that and copy and paste the authorisation code \n",
        "# from the page into the authorisation code text box\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuRvKRH9kn5s",
        "colab_type": "text"
      },
      "source": [
        "**Step 3: Whenever we work with machine learning algorithms that use a stochastic process (e.g. random numbers), it is a good idea to set the random number seed.\n",
        "Setting the random seed, results in getting the same outputs whenever you run the code. \n",
        "Setting the random seed is useful if you need to demonstrate a result, compare algorithms using the same source of randomness or to debug a part of your code. **\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDEjzHwNavrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stFb9r6kkNLX",
        "colab_type": "code",
        "outputId": "e5748550-effa-4001-b734-da778ed54285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# load the dataset\n",
        "dataset = numpy.loadtxt(\"/content/drive/My Drive/Colab Notebooks/pima.txt\", delimiter=\",\")\n",
        "print(dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
            " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
            " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
            " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
            " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3utKVAwj4Iu",
        "colab_type": "text"
      },
      "source": [
        "**Step 4: Split input (X) and output (Y) variables into separate matrices.**\n",
        "\n",
        "* **Dataset contains:** \n",
        "* **Number of input variables: 8.          Columns 0 to 7**   \n",
        "* **Number of output variables: 1.        Column 8**\n",
        "\n",
        "* **Let X be the m x n feature by case matrix. In this example a case is a person's data, a.k.a. record.**\n",
        "* **Let Y be a 1 x n vector holding all the labels. One row in Y corresponds to a row in X. So every person's record is assigned a label**\n",
        "\n",
        "**Dataset has 9 columns. Range 0:8 will select columns from 0 to 7, stopping before index 8.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBmDJLsWk64e",
        "colab_type": "code",
        "outputId": "c59b678f-11e5-4f76-9259-ded0c5800c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Split into X and Y variables\n",
        "#Input data and labels need to be separated before training/validating the model\n",
        "X = dataset[0:760,0:8]      #select rows 0 to 759 and columns 0 to 7. Columns 0 to 7 hold the input data.\n",
        "Y = dataset[0:760,8]        #select rows 0 to 759 and column 8. Column 8 is the last column holding all the labels.\n",
        "\n",
        "#The last 8 records for further testing the model  (record 760 to 767)\n",
        "X1 = dataset[760:768,0:8]   #select rows 760 to 767 and columns 0 to 7. Columns 0 to 7 hold the input data.\n",
        "Y1 = dataset[760:768,8]     #select rows 760 to 767 and column 8. Column 8 is the last column holding all the labels.\n",
        "\n",
        "#check the size of matrix X\n",
        "#dataset.shape\n",
        "X.shape\n",
        "X1.shape\n",
        "#print record of dataset X and X1\n",
        "#print(X[759])\n",
        "#print(X1[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSvPiJjpoah9",
        "colab_type": "text"
      },
      "source": [
        "**Step 5: Create the Sequential model**\n",
        "A Sequential model is a linear stack of layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25NjmEwUk9Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify the model \n",
        "#First layer in the Sequential model\n",
        "model = Sequential()\n",
        "#Dense(n) is a fully-connected layer with x hidden units.  \n",
        "#In the first layer, you must specify the expected input data shape: input_dim=8 dimensional vectors.\n",
        "\n",
        "# Line model.add(Dense(12, input_dim=8, activation='relu', name='input_layer')), does the following:\n",
        "#defines the input layer as having 8 inputs.\n",
        "#defines a hidden layer with 12 neurons, connected to the input layer that use relu activation function.\n",
        "#initializes all weights using a sample of uniform random numbers.\n",
        "\n",
        "model.add(Dense(12, input_dim=8, activation='relu', name='input_layer'))\n",
        "# now the model will take as input arrays of shape (*, 8)\n",
        "# and output arrays of shape (*, 12)\n",
        "\n",
        "# after the first layer, you don't need to specify\n",
        "# the size of the input anymore.\n",
        "\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Rrmq-G61sO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Step 6: Compile defines the loss function, the optimizer and the metrics.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KmlQzemk_uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gfkomZVorVl",
        "colab_type": "text"
      },
      "source": [
        "**Step 7: Fit the model. fit() is for training the model with the given inputs (and corresponding training labels). Adjust the number of epochs to  avoid overtraining your network.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-2INuUKlBjU",
        "colab_type": "code",
        "outputId": "56f46b4d-0d3e-4e49-86ff-582b6109c0be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "source": [
        "model.fit(X, Y, epochs=50, batch_size=10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "760/760 [==============================] - 1s 786us/step - loss: 4.1798 - acc: 0.6250\n",
            "Epoch 2/50\n",
            "760/760 [==============================] - 0s 109us/step - loss: 1.0067 - acc: 0.5789\n",
            "Epoch 3/50\n",
            "760/760 [==============================] - 0s 108us/step - loss: 0.7437 - acc: 0.6592\n",
            "Epoch 4/50\n",
            "760/760 [==============================] - 0s 107us/step - loss: 0.7028 - acc: 0.6671\n",
            "Epoch 5/50\n",
            "760/760 [==============================] - 0s 107us/step - loss: 0.6698 - acc: 0.6724\n",
            "Epoch 6/50\n",
            "760/760 [==============================] - 0s 109us/step - loss: 0.6468 - acc: 0.6829\n",
            "Epoch 7/50\n",
            "760/760 [==============================] - 0s 112us/step - loss: 0.6585 - acc: 0.6776\n",
            "Epoch 8/50\n",
            "760/760 [==============================] - 0s 115us/step - loss: 0.6337 - acc: 0.6842\n",
            "Epoch 9/50\n",
            "760/760 [==============================] - 0s 122us/step - loss: 0.6258 - acc: 0.7013\n",
            "Epoch 10/50\n",
            "760/760 [==============================] - 0s 114us/step - loss: 0.6190 - acc: 0.6961\n",
            "Epoch 11/50\n",
            "760/760 [==============================] - 0s 121us/step - loss: 0.6186 - acc: 0.6816\n",
            "Epoch 12/50\n",
            "760/760 [==============================] - 0s 120us/step - loss: 0.6189 - acc: 0.6868\n",
            "Epoch 13/50\n",
            "760/760 [==============================] - 0s 116us/step - loss: 0.6354 - acc: 0.6763\n",
            "Epoch 14/50\n",
            "760/760 [==============================] - 0s 122us/step - loss: 0.6185 - acc: 0.6842\n",
            "Epoch 15/50\n",
            "760/760 [==============================] - 0s 118us/step - loss: 0.6311 - acc: 0.6816\n",
            "Epoch 16/50\n",
            "760/760 [==============================] - 0s 118us/step - loss: 0.6085 - acc: 0.6908\n",
            "Epoch 17/50\n",
            "760/760 [==============================] - 0s 118us/step - loss: 0.5994 - acc: 0.6908\n",
            "Epoch 18/50\n",
            "760/760 [==============================] - 0s 114us/step - loss: 0.5954 - acc: 0.7013\n",
            "Epoch 19/50\n",
            "760/760 [==============================] - 0s 118us/step - loss: 0.5755 - acc: 0.7105\n",
            "Epoch 20/50\n",
            "760/760 [==============================] - 0s 113us/step - loss: 0.5958 - acc: 0.7039\n",
            "Epoch 21/50\n",
            "760/760 [==============================] - 0s 104us/step - loss: 0.5698 - acc: 0.7211\n",
            "Epoch 22/50\n",
            "760/760 [==============================] - 0s 109us/step - loss: 0.5851 - acc: 0.7079\n",
            "Epoch 23/50\n",
            "760/760 [==============================] - 0s 114us/step - loss: 0.5725 - acc: 0.6947\n",
            "Epoch 24/50\n",
            "760/760 [==============================] - 0s 109us/step - loss: 0.5681 - acc: 0.7303\n",
            "Epoch 25/50\n",
            "760/760 [==============================] - 0s 113us/step - loss: 0.5711 - acc: 0.7171\n",
            "Epoch 26/50\n",
            "760/760 [==============================] - 0s 109us/step - loss: 0.5658 - acc: 0.7171\n",
            "Epoch 27/50\n",
            "760/760 [==============================] - 0s 114us/step - loss: 0.5556 - acc: 0.7211\n",
            "Epoch 28/50\n",
            "760/760 [==============================] - 0s 113us/step - loss: 0.5669 - acc: 0.7132\n",
            "Epoch 29/50\n",
            "760/760 [==============================] - 0s 110us/step - loss: 0.5578 - acc: 0.7171\n",
            "Epoch 30/50\n",
            "760/760 [==============================] - 0s 114us/step - loss: 0.5586 - acc: 0.7263\n",
            "Epoch 31/50\n",
            "760/760 [==============================] - 0s 110us/step - loss: 0.5780 - acc: 0.7026\n",
            "Epoch 32/50\n",
            "760/760 [==============================] - 0s 113us/step - loss: 0.5509 - acc: 0.7289\n",
            "Epoch 33/50\n",
            "760/760 [==============================] - 0s 109us/step - loss: 0.5498 - acc: 0.7276\n",
            "Epoch 34/50\n",
            "760/760 [==============================] - 0s 112us/step - loss: 0.5492 - acc: 0.7263\n",
            "Epoch 35/50\n",
            "760/760 [==============================] - 0s 115us/step - loss: 0.5393 - acc: 0.7395\n",
            "Epoch 36/50\n",
            "760/760 [==============================] - 0s 125us/step - loss: 0.5466 - acc: 0.7250\n",
            "Epoch 37/50\n",
            "760/760 [==============================] - 0s 112us/step - loss: 0.5384 - acc: 0.7237\n",
            "Epoch 38/50\n",
            "760/760 [==============================] - 0s 110us/step - loss: 0.5469 - acc: 0.7329\n",
            "Epoch 39/50\n",
            "760/760 [==============================] - 0s 108us/step - loss: 0.5479 - acc: 0.7408\n",
            "Epoch 40/50\n",
            "760/760 [==============================] - 0s 112us/step - loss: 0.5447 - acc: 0.7237\n",
            "Epoch 41/50\n",
            "760/760 [==============================] - 0s 111us/step - loss: 0.5378 - acc: 0.7276\n",
            "Epoch 42/50\n",
            "760/760 [==============================] - 0s 112us/step - loss: 0.5297 - acc: 0.7395\n",
            "Epoch 43/50\n",
            "760/760 [==============================] - 0s 110us/step - loss: 0.5323 - acc: 0.7184\n",
            "Epoch 44/50\n",
            "760/760 [==============================] - 0s 111us/step - loss: 0.5526 - acc: 0.7105\n",
            "Epoch 45/50\n",
            "760/760 [==============================] - 0s 106us/step - loss: 0.5312 - acc: 0.7276\n",
            "Epoch 46/50\n",
            "760/760 [==============================] - 0s 117us/step - loss: 0.5532 - acc: 0.7289\n",
            "Epoch 47/50\n",
            "760/760 [==============================] - 0s 110us/step - loss: 0.5281 - acc: 0.7395\n",
            "Epoch 48/50\n",
            "760/760 [==============================] - 0s 110us/step - loss: 0.5322 - acc: 0.7342\n",
            "Epoch 49/50\n",
            "760/760 [==============================] - 0s 111us/step - loss: 0.5715 - acc: 0.7066\n",
            "Epoch 50/50\n",
            "760/760 [==============================] - 0s 111us/step - loss: 0.5266 - acc: 0.7513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f30223822b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbQcdVchozAV",
        "colab_type": "text"
      },
      "source": [
        "**Step 8: Evaluate the model. evaluate() is for evaluating the already trained model using the validation data and the corresponding labels. Returns the loss value and metrics values for the model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrKN4vNjlDFU",
        "colab_type": "code",
        "outputId": "ba88f034-0123-4a7b-9439-d5f96cd10dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "760/760 [==============================] - 0s 165us/step\n",
            "\n",
            "acc: 75.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4Fq-g2qpsb2",
        "colab_type": "text"
      },
      "source": [
        "**Step 9: Predict on previously unseen data. predict() is for the actual prediction. It generates output predictions for the input samples.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdoCBfuiqRkV",
        "colab_type": "code",
        "outputId": "c42c98aa-734d-452e-afe4-34f72762d5bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# calculate predictions\n",
        "#X1 data was not used to train or validate the model. Here we test the model using new data, X1. \n",
        "predictions = model.predict(X1)\n",
        "# round predictions\n",
        "rounded = [round(x1[0]) for x1 in predictions]\n",
        "print(rounded)\n",
        "\n",
        "#Simple confusion matrix using sklearn.metrics \n",
        "results = confusion_matrix(Y1, rounded)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[[5 1]\n",
            " [1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex7PINigW1Og",
        "colab_type": "text"
      },
      "source": [
        "**Here is the code for creating your own confusion matrix.**\n",
        "The code was taken from https://machinelearningmastery.com/implement-machine-learning-algorithm-performance-metrics-scratch-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WNKvD8bWz-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example of Calculating and Displaying a better looking Confusion Matrix\n",
        "\n",
        "#def defines a function for calculating the confusion matrix\n",
        "# calculate a confusion matrix\n",
        "def confusion_matrix(actual, predicted):\n",
        "\tunique = set(actual)\n",
        "\tmatrix = [list() for x in range(len(unique))]\n",
        "\tfor i in range(len(unique)):\n",
        "\t\tmatrix[i] = [0 for x in range(len(unique))]\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tx = lookup[actual[i]]\n",
        "\t\ty = lookup[predicted[i]]\n",
        "\t\tmatrix[y][x] += 1\n",
        "\treturn unique, matrix\n",
        " \n",
        "# pretty print a confusion matrix\n",
        "def print_confusion_matrix(unique, matrix):\n",
        "\tprint('(A)' + ' '.join(str(x) for x in unique))\n",
        "\tprint('(P)---')\n",
        "\tfor i, x in enumerate(unique):\n",
        "\t\tprint(\"%s| %s\" % (x, ' '.join(str(x) for x in matrix[i])))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF97weplXI6w",
        "colab_type": "text"
      },
      "source": [
        " **Step 10: Use the confusion_matrix function to print confusion matrices for the  Predict step (Step 9)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn8BrvxQXG2_",
        "colab_type": "code",
        "outputId": "20e31438-f3d1-4a13-8445-8392f810149f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Test confusion matrix for the Evaluate results\n",
        "unique, matrix = confusion_matrix(Y1, rounded)\n",
        "print_confusion_matrix(unique, matrix)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(A)0.0 1.0\n",
            "(P)---\n",
            "0.0| 5 1\n",
            "1.0| 1 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qj6zFGLlENM",
        "colab_type": "code",
        "outputId": "14a046ea-b464-44a0-95bf-5818ffa69741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Print the Sequential model structure\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jOK1cJbxBlU",
        "colab_type": "text"
      },
      "source": [
        "**Step 10: How to install the GraphViz Library  http://www.graphviz.org/**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPlJouVfpcIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -q pydot\n",
        "from keras.utils.vis_utils import plot_model\n",
        "#Prints the model to a file in the directory\n",
        "plot_model(model, to_file='/content/drive/My Drive/Colab Notebooks/model_plot3.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FACsq3Oh_xDD",
        "colab_type": "text"
      },
      "source": [
        "**Further Reading:**\n",
        "About Colab: https://www.youtube.com/watch?v=inN8seMm7UI\n",
        "\n",
        "Examples to run:\n",
        "\n",
        "https://keras.io/getting-started/sequential-model-guide/#examples\n",
        "\n",
        "In the examples, you will also find example models for real datasets:\n",
        "\n",
        "* CIFAR10 small images classification: Convolutional Neural Network (CNN) with realtime data augmentation\n",
        "\n",
        "* IMDB movie review sentiment classification: LSTM over sequences of words\n",
        "Reuters newswires topic classification: Multilayer Perceptron (MLP)\n",
        "\n",
        "* MNIST handwritten digits classification: MLP & CNN\n",
        "Character-level text generation with LSTM\n"
      ]
    }
  ]
}